{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi # 命令查看 GPU 状态\n",
        "\n",
        "print(\"GPU 是否可用：\", tf.test.is_gpu_available())"
      ],
      "metadata": {
        "id": "HMSNe4Uc2R5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5468ad67-cb1e-459c-b345-b2b55bb89a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 24 10:00:59 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-e03f626e775f>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 是否可用： True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB4AIEIcjGjU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Input, Dropout, LayerNormalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(pos, k, d):\n",
        "    i = k // 2\n",
        "    angles = pos/(np.power(10000, (2*i/d)))\n",
        "    return angles\n",
        "def positional_encoding(positions, d):\n",
        "    angle_rads = get_angles(np.arange(positions)[:, np.newaxis],np.arange(d)[np.newaxis,:],d)\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "def create_padding_mask_nmt(decoder_token_ids):\n",
        "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 36), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "def create_look_ahead_mask(sequence_length):\n",
        "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
        "    return mask\n",
        "def FullyConnected(embedding_dim, fully_connected_dim):\n",
        "    return tf.keras.Sequential([tf.keras.layers.Dense(fully_connected_dim, activation='relu'),\n",
        "                                tf.keras.layers.Dense(embedding_dim)])"
      ],
      "metadata": {
        "id": "XJ_y6r4IjYU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/variables.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "dataset = data['dataset']\n",
        "human_vocab = data['human_vocab']\n",
        "machine_vocab = data['machine_vocab']\n",
        "inv_machine_vocab = data['inv_machine_vocab']\n",
        "X = data['X']\n",
        "Y = data['Y']\n",
        "Xoh = data['Xoh']\n",
        "Yoh = data['Yoh']"
      ],
      "metadata": {
        "id": "Pn43X_sIjY3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "print(\"Source date:\", dataset[index][0])\n",
        "print(\"Target date:\", dataset[index][1])\n",
        "print(\"Source after preprocessing (indices):\", X[index])\n",
        "print(\"Target after preprocessing (indices):\", Y[index])\n",
        "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
        "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWWpOnLJjY54",
        "outputId": "f542e722-14bd-4365-ab3a-4208b2e41612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source date: 9 may 1998\n",
            "Target date: 1998-05-09\n",
            "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
            " 36 36 36 36 36 36]\n",
            "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
            "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LFOrSckmlSo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads, ffn_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim // num_heads,\n",
        "                        dropout=dropout_rate)\n",
        "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
        "        self.ffn = FullyConnected(embedding_dim, fully_connected_dim=ffn_dim)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "    def call(self, x, enc_padding_mask, training):\n",
        "        # Multi-head attention + skip connection + LayerNorm\n",
        "        attn_output = self.mha(x, x, x, attention_mask=enc_padding_mask,\n",
        "                    training = training)\n",
        "        # (batch, seq_len, embed_dim)\n",
        "        attn_output = self.dropout1(attn_output, training = training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        # Feedforward + skip connection + LayerNorm\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "        return out2\n",
        "\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_vocab_size, max_positional_encoding_input, num_encoder_layers,\n",
        "                 embedding_dim, num_heads, ffn_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_encoder_layers\n",
        "        self.embedding = Embedding(input_vocab_size, self.embedding_dim)\n",
        "        self.pos_encoding = positional_encoding(max_positional_encoding_input, self.embedding_dim)\n",
        "        self.encoder_layers = [\n",
        "            TransformerEncoderLayer(embedding_dim, num_heads, ffn_dim, dropout_rate, layernorm_eps)\n",
        "            for _ in range(self.num_layers)\n",
        "        ]\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "    def call(self, x, enc_padding_mask, training):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training=training)\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x, enc_padding_mask, training=training)\n",
        "        return x\n",
        "\n",
        "class TransformerDecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads, ffn_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.self_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim//num_heads,\n",
        "                                dropout=dropout_rate)\n",
        "        self.cross_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim//num_heads,\n",
        "                                dropout=dropout_rate)\n",
        "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
        "        self.layernorm3 = LayerNormalization(epsilon=layernorm_eps)\n",
        "        self.ffn = FullyConnected(embedding_dim=embedding_dim, fully_connected_dim=ffn_dim)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "        self.dropout3 = Dropout(dropout_rate)\n",
        "    def call(self, x, enc_output, enc_padding_mask, dec_lookahead_mask, training):\n",
        "        # 1. masked self-attention\n",
        "        attn1, attn_weights_block1 = self.self_attention(x, x, x, attention_mask = dec_lookahead_mask,\n",
        "                                training=training, return_attention_scores=True)\n",
        "        attn1 = self.dropout1(attn1, training = training)\n",
        "        out1 = self.layernorm1(x + attn1)\n",
        "        # 2. encoder-decoder attention\n",
        "        attn2, attn_weights_block2 = self.cross_attention(out1, enc_output, enc_output,\n",
        "                                attention_mask = enc_padding_mask,\n",
        "                                training = training, return_attention_scores=True)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(out1 + attn2)\n",
        "        # 3. feed-forward\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(out2 + ffn_output)\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, target_vocab_size, max_positional_encoding_target, num_decoder_layers, embedding_dim,\n",
        "            num_heads, ffn_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_decoder_layers\n",
        "        self.embedding = Embedding(target_vocab_size, self.embedding_dim)\n",
        "        self.pos_encoding = positional_encoding(max_positional_encoding_target, self.embedding_dim)\n",
        "        self.decoder_layers = [\n",
        "            TransformerDecoderLayer(embedding_dim, num_heads, ffn_dim, dropout_rate)\n",
        "            for _ in range(self.num_layers)\n",
        "        ]\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "    def call(self, x, enc_output, enc_padding_mask, dec_lookahead_mask, training):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training=training)\n",
        "        attention_weights = {}\n",
        "        for i, layer in enumerate(self.decoder_layers):\n",
        "            x, attn1, attn2 = layer(x, enc_output, enc_padding_mask, dec_lookahead_mask, training=training)\n",
        "            attention_weights[f\"decoder_layer{i+1}_attn1\"] = attn1\n",
        "            attention_weights[f\"decoder_layer{i+1}_attn2\"] = attn2\n",
        "        return x, attention_weights\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, input_vocab_size, target_vocab_size, max_positional_encoding_input,\n",
        "           max_positional_encoding_target, num_encoder_layers, num_decoder_layers, embedding_dim,\n",
        "            num_heads, ffn_dim,dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.encoder = TransformerEncoder(input_vocab_size = input_vocab_size,\n",
        "                        max_positional_encoding_input = max_positional_encoding_input,\n",
        "                        num_encoder_layers = num_encoder_layers,\n",
        "                        embedding_dim = embedding_dim,\n",
        "                        num_heads = num_heads, ffn_dim = ffn_dim,\n",
        "                        dropout_rate = dropout_rate, layernorm_eps = layernorm_eps)\n",
        "        self.decoder = TransformerDecoder(target_vocab_size = target_vocab_size,\n",
        "                        max_positional_encoding_target = max_positional_encoding_target,\n",
        "                        num_decoder_layers = num_decoder_layers,\n",
        "                        embedding_dim = embedding_dim,\n",
        "                        num_heads = num_heads, ffn_dim = ffn_dim,\n",
        "                        dropout_rate = dropout_rate, layernorm_eps = layernorm_eps)\n",
        "        self.final_layer = Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, enc_input, dec_input, enc_padding_mask, dec_lookahead_mask, training):\n",
        "        # Encoder forward\n",
        "        enc_output = self.encoder(enc_input, enc_padding_mask, training=training)\n",
        "        # Decoder forward\n",
        "        dec_output, attention_weights = self.decoder(dec_input, enc_output, enc_padding_mask,\n",
        "                                dec_lookahead_mask, training=training)\n",
        "        logits = self.final_layer(dec_output)\n",
        "        return logits, attention_weights"
      ],
      "metadata": {
        "id": "MuvO1cxalSrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.convert_to_tensor(X[:3], dtype=tf.int32)\n",
        "print(\"Encoder Input's shape =\", x.shape)   # Shape: (3, 30)\n",
        "enc_padding_mask = create_padding_mask_nmt(x)\n",
        "print(\"enc_padding_mask's shape =\", enc_padding_mask.shape)  # TensorShape([3, 1, 1, 30])\n",
        "\n",
        "machine_vocab[\"<sos>\"] = 11 # sos_id\n",
        "machine_vocab[\"<eos>\"] = 12 # eos_id\n",
        "sos_id = 11\n",
        "eos_id = 12\n",
        "# 原始 Y 是完整目标，直接 prepend <sos> → (10000, 11)\n",
        "Y_input = np.concatenate([np.full((Y.shape[0], 1), sos_id), Y], axis=1)\n",
        "print(\"Y_input's shape =\", Y_input.shape)\n",
        "# append <eos> → (10000, 11)\n",
        "Y_target = np.concatenate([Y, np.full((Y.shape[0], 1), eos_id)], axis=1)\n",
        "print(\"Y_target's shape =\", Y_target.shape)\n",
        "\n",
        "y = tf.convert_to_tensor(Y_input[:3], dtype=tf.int32)\n",
        "print(\"Decoder Input's shape =\", y.shape)    # Shape: (3, 11)\n",
        "dec_lookahead_mask = create_look_ahead_mask(11)\n",
        "print(\"dec_lookahead_mask's shape =\", dec_lookahead_mask.shape)  # (1,11,11)"
      ],
      "metadata": {
        "id": "ee8RWx1KlSuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ef9b46-f3f4-47c4-e4b9-7f99e4d1226d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input's shape = (3, 30)\n",
            "enc_padding_mask's shape = (3, 1, 1, 30)\n",
            "Y_input's shape = (10000, 11)\n",
            "Y_target's shape = (10000, 11)\n",
            "Decoder Input's shape = (3, 11)\n",
            "dec_lookahead_mask's shape = (1, 11, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(human_vocab)\n",
        "print(machine_vocab)"
      ],
      "metadata": {
        "id": "9XzPl-BalSxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ba4335-a967-409e-a807-f4453796f7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, '.': 1, '/': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'y': 34, '<unk>': 35, '<pad>': 36}\n",
            "{'-': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '<sos>': 11, '<eos>': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = len(human_vocab)\n",
        "target_vocab_size = len(machine_vocab)\n",
        "\n",
        "transformer = Transformer(input_vocab_size = input_vocab_size, target_vocab_size = target_vocab_size,\n",
        "            max_positional_encoding_input = 30, max_positional_encoding_target = 11,\n",
        "            num_encoder_layers = 2, num_decoder_layers = 2,\n",
        "            embedding_dim = 32, num_heads = 8, ffn_dim = 64, dropout_rate=0.1, layernorm_eps=1e-6)\n",
        "\n",
        "logits, attn_weights = transformer(enc_input = x, dec_input = y,\n",
        "            enc_padding_mask = enc_padding_mask, dec_lookahead_mask = dec_lookahead_mask, training = True)\n",
        "print(logits.shape)  # should be: (batch_size, target_seq_len, target_vocab_size) (3,11,13)"
      ],
      "metadata": {
        "id": "JWgNoNJV2lqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ec72be-dc88-40fc-e3a1-143297399dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 11, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred, eos_token_id=12):\n",
        "    mask = tf.cast(real != eos_token_id, dtype=tf.float32)\n",
        "    loss_ = loss_object(real, pred)  # (batch_size, target_seq_len)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "2ekpZuly2mDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(enc_input, dec_input, dec_output, enc_padding_mask, dec_lookahead_mask):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits, _ = transformer(enc_input, dec_input, enc_padding_mask, dec_lookahead_mask, training=True)\n",
        "        loss = loss_function(dec_output, logits, eos_token_id=12)\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "yMPPZUHa2mGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "8gJipWViwXS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y = tf.convert_to_tensor(Y_input[:3], dtype=tf.int32)  # Shape: (3, 11)\n",
        "y_true = tf.convert_to_tensor(Y_target[:3], dtype=tf.int32) # (3,11)\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 3\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train_step(enc_input = x,\n",
        "                dec_input = y,               # input 给 decoder\n",
        "                dec_output = y_true,            # 目标输出（标签）\n",
        "                enc_padding_mask = enc_padding_mask,\n",
        "                dec_lookahead_mask = dec_lookahead_mask)\n",
        "    print(f\"Epoch {epoch+1} Loss: {loss.numpy():.2f}\")"
      ],
      "metadata": {
        "id": "y5lpNdu_2mJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15682ea6-b116-4b35-883d-314034a5a4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 2.73\n",
            "Epoch 2 Loss: 2.52\n",
            "Epoch 3 Loss: 2.39\n",
            "Epoch 4 Loss: 2.19\n",
            "Epoch 5 Loss: 2.11\n",
            "Epoch 6 Loss: 1.96\n",
            "Epoch 7 Loss: 1.88\n",
            "Epoch 8 Loss: 1.76\n",
            "Epoch 9 Loss: 1.75\n",
            "Epoch 10 Loss: 1.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def string_to_int(string, length, vocab):\n",
        "    \"\"\"\n",
        "    Converts all strings in the vocabulary into a list of integers representing the positions of the\n",
        "    input string's characters in the \"vocab\"\n",
        "\n",
        "    Arguments:\n",
        "    string -- input string, e.g. 'Wed 10 Jul 2007'\n",
        "    length -- the number of time steps you'd like, determines if the output will be padded or cut\n",
        "    vocab -- vocabulary, dictionary used to index every character of your \"string\"\n",
        "\n",
        "    Returns:\n",
        "    rep -- list of integers (or '<unk>') (size = length) representing the position of the string's character in the vocabulary\n",
        "    \"\"\"\n",
        "\n",
        "    #make lower to standardize\n",
        "    string = string.lower()\n",
        "    string = string.replace(',','')\n",
        "\n",
        "    if len(string) > length:\n",
        "        string = string[:length]\n",
        "\n",
        "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "\n",
        "    if len(string) < length:\n",
        "        rep += [vocab['<pad>']] * (length - len(string))\n",
        "\n",
        "    #print (rep)\n",
        "    return rep"
      ],
      "metadata": {
        "id": "LoqSqWv4Kvs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indices_to_date(indices, inv_machine_vocab, eos_id=12):\n",
        "    date_tokens = []\n",
        "    for idx in indices:\n",
        "        if idx == eos_id:\n",
        "            break\n",
        "        date_tokens.append(inv_machine_vocab.get(idx, '<unk>'))\n",
        "    return ''.join(date_tokens)\n",
        "\n",
        "def predict(transformer, enc_input, max_target_len, sos_id, eos_id, target_vocab_size):\n",
        "    batch_size = tf.shape(enc_input)[0]\n",
        "    enc_padding_mask = create_padding_mask_nmt(enc_input)  # (batch_size, 1, 1, source_seq_len)\n",
        "    dec_input = tf.ones((batch_size, 1), dtype=tf.int32) * sos_id  # (batch_size, 1)\n",
        "    output = []\n",
        "\n",
        "    for t in range(max_target_len):\n",
        "        dec_mask = create_look_ahead_mask(tf.shape(dec_input)[1])  # (1, seq_len, seq_len)\n",
        "        logits, _ = transformer(enc_input, dec_input, enc_padding_mask, dec_mask, training=False)\n",
        "        last_logits = logits[:, -1, :]  # (batch_size, target_vocab_size)\n",
        "        predicted_id = tf.argmax(last_logits, axis=-1, output_type=tf.int32)  # (batch_size,)\n",
        "        output.append(predicted_id.numpy())\n",
        "        if tf.reduce_all(predicted_id == eos_id):\n",
        "            break\n",
        "        predicted_id = tf.expand_dims(predicted_id, 1)  # (batch_size, 1)\n",
        "        dec_input = tf.concat([dec_input, predicted_id], axis=1)  # (batch_size, seq_len+1)\n",
        "\n",
        "    output = np.stack(output, axis=1)  # (batch_size, max_target_len)\n",
        "    return output"
      ],
      "metadata": {
        "id": "sKGzUvqnKwfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试推理\n",
        "x_test = tf.convert_to_tensor(X[:3], dtype=tf.int32)  # (3, 30)\n",
        "predictions = predict(transformer, x_test, max_target_len=10, sos_id=11, eos_id=12, target_vocab_size=len(machine_vocab))"
      ],
      "metadata": {
        "id": "tXprek8I2mNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5994340-6c15-493e-a708-9d5dddce808e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 3 of a tensor of shape (3, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 转换为日期字符串\n",
        "for i in range(len(predictions)):\n",
        "    #source_date = ''.join([inv_human_vocab.get(idx, '<unk>') for idx in X[i] if idx != 36])\n",
        "    source_date = dataset[i][0]\n",
        "    predicted_date = indices_to_date(predictions[i], inv_machine_vocab, eos_id=12)\n",
        "    print(f\"源日期: {source_date}\")\n",
        "    print(f\"预测日期: {predicted_date}\")\n",
        "    print(\"len(predicted_date) =\", len(predicted_date))\n",
        "    print(f\"目标日期: {indices_to_date(Y_target[i], inv_machine_vocab, eos_id=12)}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "7SFz619Y2mRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9cde56-7283-4d16-dc80-998267a20039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "源日期: 9 may 1998\n",
            "预测日期: 009-111099\n",
            "len(predicted_date) = 10\n",
            "目标日期: 1998-05-09\n",
            "\n",
            "源日期: 10.11.19\n",
            "预测日期: 199-111199\n",
            "len(predicted_date) = 10\n",
            "目标日期: 2019-11-10\n",
            "\n",
            "源日期: 9/10/70\n",
            "预测日期: 009-111099\n",
            "len(predicted_date) = 10\n",
            "目标日期: 1970-09-10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FITGGEbxLAs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.convert_to_tensor(X, dtype=tf.int32)\n",
        "print(\"Encoder Input's shape =\", x.shape)   # Shape: (m, 30)\n",
        "enc_padding_mask = create_padding_mask_nmt(x)\n",
        "print(\"enc_padding_mask's shape =\", enc_padding_mask.shape)  # TensorShape([m, 1, 1, 30])\n",
        "\n",
        "machine_vocab[\"<sos>\"] = 11 # sos_id\n",
        "machine_vocab[\"<eos>\"] = 12 # eos_id\n",
        "sos_id = 11\n",
        "eos_id = 12\n",
        "# 原始 Y 是完整目标，直接 prepend <sos> → (10000, 11)\n",
        "Y_input = np.concatenate([np.full((Y.shape[0], 1), sos_id), Y], axis=1)\n",
        "print(\"Y_input's shape =\", Y_input.shape)\n",
        "# append <eos> → (10000, 11)\n",
        "Y_target = np.concatenate([Y, np.full((Y.shape[0], 1), eos_id)], axis=1)\n",
        "print(\"Y_target's shape =\", Y_target.shape)\n",
        "\n",
        "y = tf.convert_to_tensor(Y_input, dtype=tf.int32)\n",
        "print(\"Decoder Input's shape =\", y.shape)    # Shape: (m, 11)\n",
        "dec_lookahead_mask = create_look_ahead_mask(11)\n",
        "print(\"dec_lookahead_mask's shape =\", dec_lookahead_mask.shape)  # (1,11,11)"
      ],
      "metadata": {
        "id": "qz5kOnAs2mVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1843407c-c6c5-47cc-db30-b0987895a934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input's shape = (10000, 30)\n",
            "enc_padding_mask's shape = (10000, 1, 1, 30)\n",
            "Y_input's shape = (10000, 11)\n",
            "Y_target's shape = (10000, 11)\n",
            "Decoder Input's shape = (10000, 11)\n",
            "dec_lookahead_mask's shape = (1, 11, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = tf.convert_to_tensor(Y_target, dtype=tf.int32) # (m, 11)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset2 = tf.data.Dataset.from_tensor_slices((x, y, y_true, enc_padding_mask))\n",
        "dataset2 = dataset2.cache()\n",
        "dataset2 = dataset2.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "H8ayfY84Mvzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(input_vocab_size = input_vocab_size, target_vocab_size = target_vocab_size,\n",
        "            max_positional_encoding_input = 30, max_positional_encoding_target = 11,\n",
        "            num_encoder_layers = 2, num_decoder_layers = 2,\n",
        "            embedding_dim = 128, num_heads = 8, ffn_dim = 256, dropout_rate=0.1, layernorm_eps=1e-6)"
      ],
      "metadata": {
        "id": "W0OYgi-NR_GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用一小批假的数据构建模型\n",
        "dummy_x = tf.random.uniform((1, 30), minval=0, maxval=input_vocab_size, dtype=tf.int32)\n",
        "dummy_y = tf.random.uniform((1, 11), minval=0, maxval=target_vocab_size, dtype=tf.int32)\n",
        "\n",
        "dummy_enc_mask = create_padding_mask_nmt(dummy_x)\n",
        "dummy_lookahead_mask = create_look_ahead_mask(11)\n",
        "\n",
        "_ = transformer(dummy_x, dummy_y, dummy_enc_mask, dummy_lookahead_mask, training=False)"
      ],
      "metadata": {
        "id": "moybgtM6NeMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
      ],
      "metadata": {
        "id": "4TvUO8-YOAcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(enc_input, dec_input, dec_output, enc_padding_mask, dec_lookahead_mask):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits, _ = transformer(enc_input, dec_input, enc_padding_mask, dec_lookahead_mask, training=True)\n",
        "        loss = loss_function(dec_output, logits)  # 你自己的 loss 计算函数\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "u86wHipyMxqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 18\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    for batch_x, batch_y, batch_y_true, batch_enc_padding_mask in dataset2:\n",
        "        loss = train_step(\n",
        "            enc_input = batch_x,\n",
        "            dec_input = batch_y,\n",
        "            dec_output = batch_y_true,\n",
        "            enc_padding_mask = batch_enc_padding_mask,\n",
        "            dec_lookahead_mask = dec_lookahead_mask  # 可缓存，若长度不变\n",
        "        )\n",
        "        total_loss += loss\n",
        "        num_batches += 1\n",
        "    print(f\"Epoch {epoch+1} Loss: {total_loss / num_batches:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDUDk0nPSu54",
        "outputId": "b40c90cb-de38-4e99-a3f3-ced85882642d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.10\n",
            "Epoch 2 Loss: 0.36\n",
            "Epoch 3 Loss: 0.14\n",
            "Epoch 4 Loss: 0.10\n",
            "Epoch 5 Loss: 0.08\n",
            "Epoch 6 Loss: 0.06\n",
            "Epoch 7 Loss: 0.05\n",
            "Epoch 8 Loss: 0.04\n",
            "Epoch 9 Loss: 0.04\n",
            "Epoch 10 Loss: 0.03\n",
            "Epoch 11 Loss: 0.03\n",
            "Epoch 12 Loss: 0.02\n",
            "Epoch 13 Loss: 0.02\n",
            "Epoch 14 Loss: 0.02\n",
            "Epoch 15 Loss: 0.02\n",
            "Epoch 16 Loss: 0.02\n",
            "Epoch 17 Loss: 0.01\n",
            "Epoch 18 Loss: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "\n",
        "source_list = []\n",
        "for example in EXAMPLES:\n",
        "    temp = string_to_int(example, 30, human_vocab)\n",
        "    temp = tf.convert_to_tensor(temp, dtype=tf.int32)\n",
        "    temp = tf.expand_dims(temp, 0)\n",
        "    source_list.append(temp)\n",
        "# Concatenate all tensors in source_list along axis 0\n",
        "source_output = tf.concat(source_list, axis=0)\n",
        "# Print the final tensor and its shape\n",
        "print(\"Shape:\", source_output.shape)\n",
        "print(source_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PdV_Cp-TL3p",
        "outputId": "58bbfb90-2c3e-470a-99a3-a6e5f1fdc044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (8, 30)\n",
            "tf.Tensor(\n",
            "[[ 6  0 24 13 34  0  4 12 10 12 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
            "  36 36 36 36 36 36]\n",
            " [ 8  0 13 27 28 21 23  0  3 12 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
            "  36 36 36 36 36 36]\n",
            " [ 5  4 30 20  0 26 18  0 13 31 19 31 29 30  0  5  3  4  9 36 36 36 36 36\n",
            "  36 36 36 36 36 36]\n",
            " [30 31 17  0  4  3  0 22 31 23  0  5  3  3 10 36 36 36 36 36 36 36 36 36\n",
            "  36 36 36 36 36 36]\n",
            " [29 13 30 31 28 16 13 34  0 24 13 34  0 12  0  5  3  4 11 36 36 36 36 36\n",
            "  36 36 36 36 36 36]\n",
            " [24 13 28 15 20  0  6  0  5  3  3  4 36 36 36 36 36 36 36 36 36 36 36 36\n",
            "  36 36 36 36 36 36]\n",
            " [24 13 28 15 20  0  6 28 16  0  5  3  3  4 36 36 36 36 36 36 36 36 36 36\n",
            "  36 36 36 36 36 36]\n",
            " [ 4  0 24 13 28 15 20  0  5  3  3  4 36 36 36 36 36 36 36 36 36 36 36 36\n",
            "  36 36 36 36 36 36]], shape=(8, 30), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试推理\n",
        "predictions2 = predict(transformer, source_output, max_target_len=10, sos_id=11, eos_id=12,\n",
        "                       target_vocab_size=len(machine_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV7_24c4XI5v",
        "outputId": "0e0a177f-8354-41a1-c099-b53850b145bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 3 of a tensor of shape (8, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 转换为日期字符串\n",
        "for i in range(len(predictions2)):\n",
        "    #source_date = ''.join([inv_human_vocab.get(idx, '<unk>') for idx in X[i] if idx != 36])\n",
        "    source_date = EXAMPLES[i]\n",
        "    predicted_date = indices_to_date(predictions2[i], inv_machine_vocab, eos_id=12)\n",
        "    print(f\"源日期: {source_date}\")\n",
        "    print(f\"预测日期: {predicted_date}\")\n",
        "    print(\"len(predicted_date) =\", len(predicted_date))\n",
        "    #print(f\"目标日期: {indices_to_date(Y_target[i], inv_machine_vocab, eos_id=12)}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "L6APq7T9XIxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f4816d-7728-48f4-8ca3-7ad35a858260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "源日期: 3 May 1979\n",
            "预测日期: 1979-05-03\n",
            "len(predicted_date) = 10\n",
            "\n",
            "源日期: 5 April 09\n",
            "预测日期: 2009-04-05\n",
            "len(predicted_date) = 10\n",
            "\n",
            "源日期: 21th of August 2016\n",
            "预测日期: 2016-08-21\n",
            "len(predicted_date) = 10\n",
            "\n",
            "源日期: Tue 10 Jul 2007\n",
            "预测日期: 2007-07-10\n",
            "len(predicted_date) = 10\n",
            "\n",
            "源日期: Saturday May 9 2018\n",
            "预测日期: 2018-05-09\n",
            "len(predicted_date) = 10\n",
            "\n",
            "源日期: March 3 2001\n",
            "预测日期: 2001-03-03\n",
            "len(predicted_date) = 10\n",
            "\n",
            "源日期: March 3rd 2001\n",
            "预测日期: 2001-03-31\n",
            "len(predicted_date) = 10\n",
            "\n",
            "源日期: 1 March 2001\n",
            "预测日期: 2001-03-01\n",
            "len(predicted_date) = 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4UvOue5XIl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/test_sameasLSTM_variables.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "test_sameasLSTM_dataset = data['test_sameasLSTM_dataset']\n",
        "test_sameasLSTM_human_vocab = data['test_sameasLSTM_human_vocab']\n",
        "test_sameasLSTM_machine_vocab = data['test_sameasLSTM_machine_vocab']\n",
        "test_sameasLSTM_inv_machine_vocab = data['test_sameasLSTM_inv_machine_vocab']"
      ],
      "metadata": {
        "id": "1XHQtUwiVbS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sameasLSTM_EXAMPLES = [i[0] for i in test_sameasLSTM_dataset]\n",
        "\n",
        "source_list = []\n",
        "for example in test_sameasLSTM_EXAMPLES:\n",
        "    temp = string_to_int(example, 30, human_vocab)\n",
        "    temp = tf.convert_to_tensor(temp, dtype=tf.int32)\n",
        "    temp = tf.expand_dims(temp, 0)\n",
        "    source_list.append(temp)\n",
        "# Concatenate all tensors in source_list along axis 0\n",
        "source_output = tf.concat(source_list, axis=0)\n",
        "# Print the final tensor and its shape\n",
        "print(\"Shape:\", source_output.shape)\n",
        "#print(source_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0xlxrwmNTnA",
        "outputId": "f04d6be6-8438-48db-f1ff-593022e90672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (2000, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试推理\n",
        "predictions3 = predict(transformer, source_output, max_target_len=10, sos_id=11, eos_id=12,\n",
        "                       target_vocab_size=len(machine_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Kw5XqrOIwo",
        "outputId": "8b7360d3-6e94-41ab-ca2b-70a122851447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 3 of a tensor of shape (2000, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 转换为日期字符串\n",
        "predicted_dates = []\n",
        "for i in range(len(predictions3)):\n",
        "    #source_date = ''.join([inv_human_vocab.get(idx, '<unk>') for idx in X[i] if idx != 36])\n",
        "    #source_date = test_sameasLSTM_EXAMPLES[i]\n",
        "    predicted_date = indices_to_date(predictions3[i], inv_machine_vocab, eos_id=12)\n",
        "    predicted_dates.append(predicted_date)\n",
        "\n",
        "test_sameasLSTM_GROUND_TRUTH = [i[1] for i in test_sameasLSTM_dataset]\n",
        "\n",
        "correct = sum(p == t for p, t in zip(predicted_dates, test_sameasLSTM_GROUND_TRUTH))\n",
        "accuracy = correct / len(test_sameasLSTM_GROUND_TRUTH)\n",
        "print(f\"\\n准确率（Exact Match Accuracy）: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDI5iibDORnl",
        "outputId": "2eefaac5-cd48-457c-c2f1-7ba0e8066f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "准确率（Exact Match Accuracy）: 98.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QopiVxwkUeQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save_weights(\"transformer_epoch18.weights.h5\")"
      ],
      "metadata": {
        "id": "jGka5m_PUq1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"transformer_epoch18.weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "D64ONKxGUwVr",
        "outputId": "a7b05aa3-da9d-409c-b889-7ef3c0b14326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bd0f5d5e-f316-43b8-a28d-e9d744e06a4d\", \"transformer_epoch18.weights.h5\", 2892196)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8jwN5vC_Vijw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SML81DvPVipq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}